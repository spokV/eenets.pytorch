{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"eenets.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNbxq8/HrijaTBP/Itb//wc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"OMIVlc1Bg_4M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1608498767012,"user_tz":-120,"elapsed":743,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjttddW98hCKyx4fL0AWCIkMKe_vRZU_03xxsLQ-Q=s64","userId":"07226046456222457646"}},"outputId":"b66d760e-af48-4727-d103-3181a4793415"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WHMJCFzp0WW5","executionInfo":{"status":"ok","timestamp":1608498767353,"user_tz":-120,"elapsed":1074,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjttddW98hCKyx4fL0AWCIkMKe_vRZU_03xxsLQ-Q=s64","userId":"07226046456222457646"}},"outputId":"48fe69b2-4d35-4e4f-f6a3-e61d67e62642"},"source":["%pwd\n","%cd '/content/drive/MyDrive/afeka/Project/code/eenets/eenets.pytorch'\n","import sys\n","sys.path.append('/content/drive/MyDrive/afeka/Project/code/eenets/eenets.pytorch')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/afeka/Project/code/eenets/eenets.pytorch\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jUOEb88s3JAw","executionInfo":{"status":"ok","timestamp":1608498767355,"user_tz":-120,"elapsed":1069,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjttddW98hCKyx4fL0AWCIkMKe_vRZU_03xxsLQ-Q=s64","userId":"07226046456222457646"}}},"source":["#!python main.py --model eenet8 --dataset mnist --epochs 20 --no-save-model"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"OQ7yY1Fc0QOX","executionInfo":{"status":"ok","timestamp":1608498768098,"user_tz":-120,"elapsed":1807,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjttddW98hCKyx4fL0AWCIkMKe_vRZU_03xxsLQ-Q=s64","userId":"07226046456222457646"}}},"source":["import time\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from scipy import stats\n","from utils import load_dataset\n","from utils import adaptive_learning_rate\n","from utils import save_model\n","from utils import save_history\n","from utils import plot_history\n","from utils import print_validation\n","from init import initializer\n","from eenet import EENet\n","from custom_eenet import CustomEENet"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"STrb901v8_GR","executionInfo":{"status":"ok","timestamp":1608498768102,"user_tz":-120,"elapsed":1806,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjttddW98hCKyx4fL0AWCIkMKe_vRZU_03xxsLQ-Q=s64","userId":"07226046456222457646"}},"outputId":"133ce772-994e-4778-a339-c4829c762172"},"source":["print('Torch', torch.__version__, 'CUDA', torch.version.cuda)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Torch 1.7.0+cu101 CUDA 10.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lcAm4GdJzk_P","executionInfo":{"status":"ok","timestamp":1608498768103,"user_tz":-120,"elapsed":1801,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjttddW98hCKyx4fL0AWCIkMKe_vRZU_03xxsLQ-Q=s64","userId":"07226046456222457646"}}},"source":["def train(args, model, model_pre, train_loader, optimizer):\n","    \"\"\"train the model.\n","\n","    Arguments are\n","    * args:         command line arguments entered by user.\n","    * model:        convolutional neural network model.\n","    * train_loader: train data loader.\n","    * optimizer:    optimize the model during training.\n","    * epoch:        epoch number.\n","\n","    This trains the model and prints the results of each epochs.\n","    \"\"\"\n","    losses = []\n","    model.train()\n","    if model_pre != None:\n","        model_pre.eval()\n","    for data, target in train_loader:\n","        data, target = data.to(args.device), target.to(args.device, dtype=torch.int64)\n","        optimizer.zero_grad()\n","\n","        # training settings for EENet based models\n","        if isinstance(model, (CustomEENet, EENet)):\n","            pred, conf, cost = model(data)\n","            \n","            if args.use_main_targets:\n","                _, target_main = torch.max(pred[args.num_ee], 1)#np.argmax(pred[args.num_ee], axis=1)\n","                # Calculate cumulative prediction and cost during training\n","                cum_pred = [None] * args.num_ee + [pred[args.num_ee]]\n","                cum_cost = [None] * args.num_ee + [torch.tensor(1.0).to(args.device)]\n","                loss = F.nll_loss(cum_pred[-1].log(), target_main) + args.lambda_coef * cum_cost[-1].mean()\n","                for i in range(args.num_ee - 1, -1, -1):\n","                    cum_pred[i] = conf[i] * pred[i] + (1 - conf[i]) * cum_pred[i + 1]\n","                    cum_cost[i] = conf[i] * cost[i] + (1 - conf[i]) * cum_cost[i + 1]\n","                    loss += F.nll_loss(cum_pred[i].log(), target_main) + args.lambda_coef * cum_cost[i].mean()\n","            else:\n","                if args.ee_disable:\n","                    loss = F.cross_entropy(pred[args.num_ee], target)\n","                else:\n","                    # Calculate cumulative prediction and cost during training\n","                    cum_pred = [None] * args.num_ee + [pred[args.num_ee]]\n","                    cum_cost = [None] * args.num_ee + [torch.tensor(1.0).to(args.device)]\n","                    loss = F.nll_loss(cum_pred[-1].log(), target) + args.lambda_coef * cum_cost[-1].mean()\n","                    for i in range(args.num_ee - 1, -1, -1):\n","                        cum_pred[i] = conf[i] * pred[i] + (1 - conf[i]) * cum_pred[i + 1]\n","                        cum_cost[i] = conf[i] * cost[i] + (1 - conf[i]) * cum_cost[i + 1]\n","                        loss += F.nll_loss(cum_pred[i].log(), target) + args.lambda_coef * cum_cost[i].mean()\n","\n","        # training settings for other models\n","        else:\n","            pred = model(data)\n","            loss = F.cross_entropy(pred, target)\n","\n","        losses.append(float(loss))\n","        loss.backward()\n","        optimizer.step()\n","\n","    # print the training results of epoch\n","    result = {'train_loss': round(np.mean(losses), 4),\n","              'train_loss_sem': round(stats.sem(losses), 2)}\n","\n","    print('Train avg loss: {:.4f}'.format(result['train_loss']))\n","    return result"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"bQIJj29izonC","executionInfo":{"status":"ok","timestamp":1608498768104,"user_tz":-120,"elapsed":1797,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjttddW98hCKyx4fL0AWCIkMKe_vRZU_03xxsLQ-Q=s64","userId":"07226046456222457646"}}},"source":["def validate(args, model, val_loader):\n","    \"\"\"validate the model.\n","\n","    Arguments are\n","    * args:         command line arguments entered by user.\n","    * model:        convolutional neural network model.\n","    * val_loader:   validation data loader..\n","\n","    This validates the model and prints the results of each epochs.\n","    Finally, it returns average accuracy, loss and comptational cost.\n","    \"\"\"\n","    batch = {'time':[], 'cost':[], 'flop':[], 'acc':[], 'val_loss':[]}\n","    exit_points = [0]*(args.num_ee+1)\n","    # switch to evaluate mode\n","    model.eval()\n","    with torch.no_grad():\n","        for data, target in val_loader:\n","            data, target = data.to(args.device), target.to(args.device, dtype=torch.int64)\n","            # compute output\n","            start = time.process_time()\n","\n","            # results of EENet based models\n","            if isinstance(model, (EENet, CustomEENet)):\n","                pred, idx, cost = model(data)\n","                elapsed_time = time.process_time()  - start\n","                loss = F.nll_loss(pred.log(), target) + args.lambda_coef * cost\n","                flop = cost * model.complexity[-1][0]\n","                exit_points[idx] += 1\n","\n","            # results of other models\n","            else:\n","                pred = model(data)\n","                elapsed_time = time.process_time()  - start\n","                loss = F.cross_entropy(pred, target)\n","                flop, cost = model.complexity[-1][0], 1.0\n","                exit_points = None\n","\n","            # get the index of the max log-probability\n","            pred = pred.max(1, keepdim=True)[1]\n","            acc = pred.eq(target.view_as(pred)).sum().item()\n","            batch['acc'].append(acc*100.)\n","            batch['time'].append(elapsed_time)\n","            batch['cost'].append(cost*100.)\n","            batch['flop'].append(flop)\n","            batch['val_loss'].append(float(loss))\n","\n","    print_validation(args, batch, exit_points)\n","\n","    result = {}\n","    for key, value in batch.items():\n","        result[key] = round(np.mean(value), 4)\n","        result[key+'_sem'] = round(stats.sem(value), 2)\n","    return result"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"HtzRBZLwzqvB","executionInfo":{"status":"ok","timestamp":1608498768105,"user_tz":-120,"elapsed":1794,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjttddW98hCKyx4fL0AWCIkMKe_vRZU_03xxsLQ-Q=s64","userId":"07226046456222457646"}}},"source":["def run(model, model_pre, optimizer, args, train_loader, test_loader):\n","    # model, optimizer, args = initializer(local_args)\n","    # train_loader, test_loader = load_dataset(args)\n","    best = {}\n","    best_epoch = 0\n","    for epoch in range(args.start_epoch, args.epochs + 1):\n","        print('{:3d}: '.format(epoch), end='')\n","        result = {'epoch': epoch}\n","\n","        # use adaptive learning rate\n","        if args.adaptive_lr:\n","            adaptive_learning_rate(model, optimizer, epoch)\n","        result.update(train(args, model, model_pre, train_loader, optimizer))\n","\n","        # validate and keep history at each log interval\n","        if epoch % args.log_interval == 0:\n","            result.update(validate(args, model, test_loader))\n","            save_history(args, result)\n","            if not best or result['val_loss'] < best['val_loss']:\n","                best = result\n","                best_epoch = epoch\n","\n","        # save model parameters\n","        if not args.no_save_model:\n","            save_model(args, model, epoch)\n","\n","    # print the best validation result\n","    print('\\nThe best avg val_loss: {:.4f}, avg val_cost: {:.2f}%, avg val_acc: {:.2f}%\\n'\n","          .format(best['val_loss'], best['cost'], best['acc']))\n","\n","    # save the model giving the best validation results as a final model\n","    if not args.no_save_model:\n","        save_model(args, model, best_epoch, True)\n","    plot_history(args)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"6wchKooglRkV","executionInfo":{"status":"ok","timestamp":1608499581910,"user_tz":-120,"elapsed":815594,"user":{"displayName":"Assaf La","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjttddW98hCKyx4fL0AWCIkMKe_vRZU_03xxsLQ-Q=s64","userId":"07226046456222457646"}},"outputId":"163ba334-e7ab-4b98-a073-e0b5de6e30ac"},"source":["\"\"\"\n","local_args_pre = \\\n","    ['--dataset', 'mnist',\n","      '--model', 'eenet8',\n","      '--epochs', '20',\n","      '--num-ee', '2',\n","      '--filters', '4',\n","      '--lambda-coef', '0.5',\n","      '--optimizer', 'Adam',\n","      '--ee-disable',\n","      # '--plot-history',\n","      # '--no-save-model'\n","      ]\n","\n","model_pre, optimizer_pre, args_pre = initializer(local_args_pre)\n","train_loader_pre, test_loader_pre = load_dataset(args_pre)\n","run(model_pre, None optimizer_pre, args_pre, train_loader_pre, test_loader_pre)\n","\"\"\"\n","local_args_post = \\\n","    ['--dataset', 'mnist',\n","      '--model', 'eenet8',\n","      '--epochs', '20',\n","      '--num-ee', '2',\n","      '--filters', '4',\n","      '--lambda-coef', '2.0',\n","      '--optimizer', 'Adam',\n","      '--load-model', '../models/mnist/eenet8_empty_branches/model.pt',\n","      '--use-main-targets'\n","      # '--ee-disable', 'False'\n","      # '--plot-history',\n","      # '--no-save-model'\n","      ]\n","\n","model_post, optimizer_post, args_post = initializer(local_args_post)\n","#model_pre, optimizer_pre, args_post = initializer(local_args_post)\n","model_post.set_ee_disable(False)\n","model_post.initblock.requires_grad_(False)\n","model_post.basicblock1.requires_grad_(False)\n","model_post.basicblock2.requires_grad_(False)\n","model_post.basicblock3.requires_grad_(False)\n","model_post.finalblock.requires_grad_(False)\n","model_post.classifier.requires_grad_(False)\n","model_post.conv2d_6.requires_grad_(False)\n","model_post.conv2d_9.requires_grad_(False)\n","\n","train_loader_post, test_loader_post = load_dataset(args_post)\n","run(model_post, None, optimizer_post, args_post, train_loader_post, test_loader_post)\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["use cuda:  True  device:  cuda\n","ee-block-0: flops=1.79 KMac, params=407, cost-rate=0.07\n","ee-block-1: flops=6.61 KMac, params=1.4 k, cost-rate=0.26\n","exit-block: flops=25.81 KMac, params=5.33 k, cost-rate=1.00\n","  1: Train avg loss: 5.5983\n","     Test avg time: 0.1862msec; avg val_loss: 1.9498; avg val_acc: 98.06%\n","\tavg val_cost: 92.75%; exits: <272,642,9086,>\n","  2: Train avg loss: 5.5052\n","     Test avg time: 0.1748msec; avg val_loss: 2.0274; avg val_acc: 85.79%\n","\tavg val_cost: 80.31%; exits: <371,2199,7430,>\n","  3: Train avg loss: 5.4450\n","     Test avg time: 0.1638msec; avg val_loss: 2.1501; avg val_acc: 76.92%\n","\tavg val_cost: 69.00%; exits: <739,3271,5990,>\n","  4: Train avg loss: 5.4011\n","     Test avg time: 0.1559msec; avg val_loss: 2.3254; avg val_acc: 69.48%\n","\tavg val_cost: 58.95%; exits: <769,4591,4640,>\n","  5: Train avg loss: 5.3701\n","     Test avg time: 0.1552msec; avg val_loss: 2.3980; avg val_acc: 66.71%\n","\tavg val_cost: 54.62%; exits: <857,5067,4076,>\n","  6: Train avg loss: 5.3477\n","     Test avg time: 0.1500msec; avg val_loss: 2.4539; avg val_acc: 64.48%\n","\tavg val_cost: 50.90%; exits: <987,5408,3605,>\n","  7: Train avg loss: 5.3281\n","     Test avg time: 0.1457msec; avg val_loss: 2.5920; avg val_acc: 60.18%\n","\tavg val_cost: 45.51%; exits: <1126,5964,2910,>\n","  8: Train avg loss: 5.3119\n","     Test avg time: 0.1458msec; avg val_loss: 2.6035; avg val_acc: 59.77%\n","\tavg val_cost: 44.44%; exits: <1082,6163,2755,>\n","  9: Train avg loss: 5.2997\n","     Test avg time: 0.1429msec; avg val_loss: 2.6120; avg val_acc: 58.93%\n","\tavg val_cost: 42.79%; exits: <1192,6249,2559,>\n"," 10: Train avg loss: 5.2907\n","     Test avg time: 0.1414msec; avg val_loss: 2.6083; avg val_acc: 58.29%\n","\tavg val_cost: 42.08%; exits: <1281,6235,2484,>\n"," 11: Train avg loss: 5.2829\n","     Test avg time: 0.1399msec; avg val_loss: 2.6041; avg val_acc: 58.95%\n","\tavg val_cost: 42.03%; exits: <1214,6324,2462,>\n"," 12: Train avg loss: 5.2752\n","     Test avg time: 0.1387msec; avg val_loss: 2.5485; avg val_acc: 59.22%\n","\tavg val_cost: 42.71%; exits: <1486,5895,2619,>\n"," 13: Train avg loss: 5.2676\n","     Test avg time: 0.1383msec; avg val_loss: 2.6085; avg val_acc: 58.01%\n","\tavg val_cost: 40.99%; exits: <1374,6266,2360,>\n"," 14: Train avg loss: 5.2632\n","     Test avg time: 0.1351msec; avg val_loss: 2.7571; avg val_acc: 54.37%\n","\tavg val_cost: 36.95%; exits: <1421,6754,1825,>\n"," 15: Train avg loss: 5.2572\n","     Test avg time: 0.1385msec; avg val_loss: 2.8395; avg val_acc: 52.13%\n","\tavg val_cost: 34.52%; exits: <1517,6963,1520,>\n"," 16: Train avg loss: 5.2531\n","     Test avg time: 0.1384msec; avg val_loss: 2.6716; avg val_acc: 55.92%\n","\tavg val_cost: 38.63%; exits: <1476,6458,2066,>\n"," 17: Train avg loss: 5.2485\n","     Test avg time: 0.1326msec; avg val_loss: 2.7224; avg val_acc: 53.07%\n","\tavg val_cost: 36.33%; exits: <1843,6313,1844,>\n"," 18: Train avg loss: 5.2435\n","     Test avg time: 0.1303msec; avg val_loss: 2.8341; avg val_acc: 52.23%\n","\tavg val_cost: 34.30%; exits: <1556,6944,1500,>\n"," 19: Train avg loss: 5.2391\n","     Test avg time: 0.1319msec; avg val_loss: 2.8603; avg val_acc: 51.22%\n","\tavg val_cost: 33.49%; exits: <1711,6860,1429,>\n"," 20: Train avg loss: 5.2362\n","     Test avg time: 0.1301msec; avg val_loss: 2.8354; avg val_acc: 52.63%\n","\tavg val_cost: 34.33%; exits: <1631,6847,1522,>\n","\n","The best avg val_loss: 1.9498, avg val_cost: 92.75%, avg val_acc: 98.06%\n","\n","The figure is plotted under '../results/mnist/eenet8/ee2_fine/loss_figure.png'\n","The figure is plotted under '../results/mnist/eenet8/ee2_fine/acc_cost_figure.png'\n","The figure is plotted under '../results/mnist/eenet8/ee2_fine/acc_vs_flop_figure.png'\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]}]}